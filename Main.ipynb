{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNAuhq3PSLxvaAQikrAxwjX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werd0n4/hand-gesture-classification/blob/master/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWV-fQOYLdCT"
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q8kzcXXwFg7",
        "outputId": "8bbf1f57-f1fd-4838-f0e6-3eac517af26a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XymGlouwU2-"
      },
      "source": [
        "# !ls"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBEyz2mvZcZe"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import random\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ljCHYlFLKus"
      },
      "source": [
        "# Constant parameters\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgEIncCL4j8i"
      },
      "source": [
        "horiz_x = 800  \n",
        "vert_y = 600\n",
        "#drive paths\n",
        "#\n",
        "imgs_train_path = '/content/drive/My Drive/Colab Notebooks/Rozszerzony_dataset/Train/'\n",
        "imgs_test_path = '/content/drive/My Drive/Colab Notebooks/Rozszerzony_dataset/Test/'\n",
        "#local paths windows\n",
        "#\n",
        "# imgs_train_path = 'C:\\\\Users\\\\Werdon\\\\Google Drive\\\\Colab Notebooks\\\\Rozszerzony_dataset\\\\Train'\n",
        "# imgs_test_path = 'C:\\\\Users\\\\Werdon\\\\Google Drive\\\\Colab Notebooks\\\\Rozszerzony_dataset\\\\Train'\n",
        "#local paths manjaro\n",
        "#\n",
        "# imgs_train_path = '/home/werdon4/Rozszerzony_dataset/Train'\n",
        "# imgs_test_path = '/home/werdon4/Rozszerzony_dataset/Test'\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4fPPXAU7hhc"
      },
      "source": [
        "\n",
        "class_names = {\n",
        "    0: \"1\",\n",
        "    1: \"2\",\n",
        "    2: \"3\",\n",
        "    3: \"4\",\n",
        "    4: \"5\",\n",
        "    5: \"A\",\n",
        "    6: \"B\",\n",
        "    7: \"C\",\n",
        "    8: \"D\",\n",
        "    9: \"E\",\n",
        "    10: \"F\",\n",
        "    11: \"G\",\n",
        "    12: \"H\",\n",
        "    13: \"I\",\n",
        "    14: \"K\",\n",
        "    15: \"L\",\n",
        "    16: \"M\",\n",
        "    17: \"N\",\n",
        "    18: \"O\",\n",
        "    19: \"P\",\n",
        "    20: \"R\",\n",
        "    21: \"S\",\n",
        "    22: \"T\",\n",
        "    23: \"U\",\n",
        "    24: \"W\",\n",
        "    25: \"Y\",\n",
        "    26: \"Z\"\n",
        "}\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixFACs6TLptD"
      },
      "source": [
        "# Auxiliary functions\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wS1Y3LhdoCk"
      },
      "source": [
        "## Image resize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WA7zKkLxRZk"
      },
      "source": [
        "\n",
        "def resize(path):\n",
        "    img_counter = 0\n",
        "\n",
        "    for dirname in os.listdir(path): \n",
        "        for filename in os.listdir(os.path.join(path, dirname)):\n",
        "            image_path = os.path.join(path, dirname, filename)\n",
        "            img = cv2.imread(image_path)\n",
        "            resized_img = cv2.resize(img, (horiz_x, vert_y))\n",
        "            cv2.imwrite(image_path, resized_img)\n",
        "            img_counter += 1\n",
        "    \n",
        "    print('Images in set: ' + str(img_counter))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlo-plFYdu3g"
      },
      "source": [
        "## Image size sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_RAtl1TrwJL"
      },
      "source": [
        "\n",
        "def sanity_check(path):\n",
        "    counter = 0\n",
        "\n",
        "    for dirname in os.listdir(path): \n",
        "        for filename in os.listdir(os.path.join(path, dirname)):\n",
        "            image_path = os.path.join(path, dirname, filename)\n",
        "            img = cv2.imread(image_path)\n",
        "            if img.shape != (horiz_x, vert_y, 3):\n",
        "                counter += 1\n",
        "\n",
        "    print('Sanity result: ' + str(counter))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at3uxTKnHvKr"
      },
      "source": [
        "\n",
        "def show_img(index, X, Y):\n",
        "    # plt.imshow(X[index])\n",
        "    plt.imshow(cv2.cvtColor(X[index],cv2.COLOR_BGR2RGB).astype('float32'))\n",
        "    plt.show()\n",
        "    nmb = int(np.where(Y[index] == 1)[0])\n",
        "    print(\"On image: \" + class_names[nmb])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXO5S6_IL1Rp"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKpUsMrA4gkt"
      },
      "source": [
        "\n",
        "def load_dataset():\n",
        "    trainlist = glob.glob(f'{imgs_train_path}/*/*')\n",
        "    testlist = glob.glob(f'{imgs_test_path}/*/*')\n",
        "    X_train = np.array( [np.array(cv2.normalize(cv2.imread(fname), None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)) for fname in trainlist] )\n",
        "    X_test = np.array( [np.array(cv2.normalize(cv2.imread(fname), None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)) for fname in testlist] )\n",
        "\n",
        "    # Y_train = np.array([np.zeros(27) for fname in trainlist])\n",
        "    Y_train = np.array([0 for fname in trainlist])\n",
        "    for i,fname in enumerate(trainlist):\n",
        "        # print(fname)\n",
        "        img_id = fname.split('/')[7]##7 if windows 4 if manjaro\n",
        "        img_id = img_id.split('_')[0]\n",
        "        # Y_train[i][img_id] = 1\n",
        "        Y_train[i] = img_id\n",
        "\n",
        "\n",
        "    # Y_test = np.array([np.zeros(27) for fname in testlist])\n",
        "    Y_test = np.array([0 for fname in testlist])\n",
        "    for i,fname in enumerate(testlist):\n",
        "        img_id = fname.split('/')[7]\n",
        "        img_id = img_id.split('_')[0]\n",
        "        # Y_test[i][img_id] = 1\n",
        "        Y_test[i] = img_id\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "# load_dataset()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52QUbDo5L9OC"
      },
      "source": [
        "## Create network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGL1a8P5W1Ku"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    # kernel_initializer = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "    kernel_initializer=None \n",
        "    activ_func = 'relu'\n",
        "    kernel_regularizer=None\n",
        "    activity_regularizer=None\n",
        "\n",
        "    # CONVOLUTIONAL LAYER - 1\n",
        "    model.add(Conv2D(\n",
        "        filters=6, \n",
        "        kernel_size=(5,5), \n",
        "        input_shape=(vert_y, horiz_x, 3), \n",
        "        activation=activ_func,\n",
        "        # kernel_initializer=kernel_initializer\n",
        "        # kernel_regularizer=kernel_regularizer\n",
        "        # activity_regularizer=activity_regularizer\n",
        "    ))\n",
        "\n",
        "    # POOLING LAYER\n",
        "    model.add(MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    ))\n",
        "\n",
        "    # CONVOLUTIONAL LAYER - 2\n",
        "    model.add(Conv2D(\n",
        "        filters=16, \n",
        "        kernel_size=(5,5), \n",
        "        activation=activ_func,\n",
        "        # kernel_initializer=kernel_initializer\n",
        "        # kernel_regularizer=kernel_regularizer\n",
        "        # activity_regularizer=activity_regularizer\n",
        "    ))\n",
        "\n",
        "    # POOLING LAYER\n",
        "    model.add(MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    ))\n",
        "\n",
        "    # CONVOLUTIONAL LAYER - 3\n",
        "    model.add(Conv2D(\n",
        "        filters=32, \n",
        "        kernel_size=(5,5), \n",
        "        activation=activ_func,\n",
        "        # kernel_initializer=kernel_initializer\n",
        "        # kernel_regularizer=kernel_regularizer\n",
        "        # activity_regularizer=activity_regularizer\n",
        "    ))\n",
        "\n",
        "    # POOLING LAYER\n",
        "    model.add(MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    ))\n",
        "\n",
        "    # CONVOLUTIONAL LAYER - 4\n",
        "    model.add(Conv2D(\n",
        "        filters=120, \n",
        "        kernel_size=(5,5), \n",
        "        activation=activ_func,\n",
        "        # kernel_initializer=kernel_initializer\n",
        "        # kernel_regularizer=kernel_regularizer\n",
        "        # activity_regularizer=activity_regularizer\n",
        "    ))\n",
        "\n",
        "    # POOLING LAYER\n",
        "    model.add(MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    ))\n",
        "\n",
        "    # CONVOLUTIONAL LAYER - 5\n",
        "    model.add(Conv2D(\n",
        "        filters=40, \n",
        "        kernel_size=(3,3), \n",
        "        activation=activ_func,\n",
        "        # kernel_initializer=kernel_initializer\n",
        "        # kernel_regularizer=kernel_regularizer\n",
        "        # activity_regularizer=activity_regularizer\n",
        "    ))\n",
        "\n",
        "    # POOLING LAYER\n",
        "    model.add(MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    ))\n",
        "\n",
        "    ######## FLATTEN ########\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(84, activation='relu'))\n",
        "    # model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(27, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer='adam', \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aR-plpcMYMG"
      },
      "source": [
        "# Loading dataset\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c60j15t047-T"
      },
      "source": [
        "## Resize images and do sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe0BVKLffdt3"
      },
      "source": [
        "# Uncomment before first run on dataset \n",
        "# resize(imgs_train_path)\n",
        "# sanity_check(imgs_train_path)\n",
        "# resize(imgs_test_path)\n",
        "# sanity_check(imgs_test_path)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3YGc40zMT07"
      },
      "source": [
        "# X_train, Y_train, X_test, Y_test = load_dataset()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2_6niPw-o-I"
      },
      "source": [
        "# One hot encoding\n",
        "# Y_cat_train = to_categorical(Y_train, 27)\n",
        "# Y_cat_test = to_categorical(Y_test, 27)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZbm9XBKCPtn"
      },
      "source": [
        "## Data augumentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRThxI7Y8qKw"
      },
      "source": [
        "## Initializing ImageDataGenerator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0PtMORrCPDN"
      },
      "source": [
        "image_gen = ImageDataGenerator(rotation_range=5, # rotate the image 20 degrees\n",
        "                               width_shift_range=0.05, # Shift the pic width by a max of 5%\n",
        "                               height_shift_range=0.05, # Shift the pic height by a max of 5%\n",
        "                            #    rescale=1.1, # Rescale the image by normalzing it.\n",
        "                               shear_range=0.05, # Shear means cutting away part of the image (max 10%)\n",
        "                               zoom_range=0.05, # Zoom in by 10% max\n",
        "                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n",
        "                                )\n",
        "                              "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryU4cvqRuDJL"
      },
      "source": [
        "## Augumentation sample result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2dLQoeLEgOq"
      },
      "source": [
        "#augumentation sample result\n",
        "\n",
        "#original img\n",
        "# nmb = random.randint(0, 296)\n",
        "# my_hand = X_test[nmb]\n",
        "# show_img(nmb, X_test, Y_cat_test)\n",
        "\n",
        "# #generated img\n",
        "# gen_img = image_gen.random_transform(my_hand)\n",
        "# print(\"Generated image\")\n",
        "# plt.imshow(cv2.cvtColor(gen_img,cv2.COLOR_BGR2RGB).astype('float32'))\n",
        "# plt.show()\n",
        "\n",
        "# comparison = my_hand == gen_img\n",
        "# equal_arrays = comparison.all()\n",
        "# print(\"Images are equal?: \" + str(equal_arrays))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM2dXXIsuIRj"
      },
      "source": [
        "## Image shape and batch size initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHoIHLMFMP_3",
        "outputId": "30c2f996-3069-4340-f2da-71edb721af30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "image_shape = (horiz_x, vert_y, 3)\n",
        "batch_size = 16\n",
        "\n",
        "print(imgs_train_path)\n",
        "print(imgs_test_path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Rozszerzony_dataset/Train/\n",
            "/content/drive/My Drive/Colab Notebooks/Rozszerzony_dataset/Test/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnjTP4lG82TX"
      },
      "source": [
        "## Initializing test and train image geneartors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re4ZJ1TZTm4o",
        "outputId": "cb72de66-8ae8-4118-c1bf-a583b37b1e3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_image_gen = image_gen.flow_from_directory(imgs_train_path,\n",
        "                                               target_size=image_shape[:2],\n",
        "                                                color_mode='rgb',\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode='categorical')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1561 images belonging to 27 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrWwYpgUTm4r",
        "outputId": "6e6ca5ac-28b4-4c50-89ee-7077d34fcd31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_image_gen = image_gen.flow_from_directory(imgs_test_path,\n",
        "                                               target_size=image_shape[:2],\n",
        "                                               color_mode='rgb',\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode='categorical',shuffle=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 297 images belonging to 27 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdwaoT7yMuME"
      },
      "source": [
        "#train_image_gen.class_indices"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYxO9mzpMfAc"
      },
      "source": [
        "# Create and train model\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPcKT1LCpeaO",
        "outputId": "cc22cc52-0d6f-4eac-ee43-e677f4c266d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "CNN = create_model()\n",
        "CNN.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 596, 796, 6)       456       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 298, 398, 6)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 294, 394, 16)      2416      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 147, 197, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 143, 193, 32)      12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 71, 96, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 67, 92, 120)       96120     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 33, 46, 120)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 31, 44, 40)        43240     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 22, 40)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 13200)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1689728   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10836     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 27)                2295      \n",
            "=================================================================\n",
            "Total params: 1,857,923\n",
            "Trainable params: 1,857,923\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70Mj2Adg6WR6"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "#Y_cat_train.shape"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxzkZIjI8-SR"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhC9fdDfi5V"
      },
      "source": [
        "# CNN.fit(X_train, Y_cat_train, epochs=12, validation_data=(X_test, Y_cat_test), batch_size=batch_size, callbacks=[early_stop])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbhE5_p19EkS"
      },
      "source": [
        "## Fit model with data augumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9OcwzpmM-Fw",
        "outputId": "72408360-6e90-49a3-f01e-c41e6593410c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results = CNN.fit(train_image_gen, epochs=20, validation_data=test_image_gen, callbacks=[early_stop])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "98/98 [==============================] - 185s 2s/step - loss: 3.3432 - accuracy: 0.0448 - val_loss: 3.2871 - val_accuracy: 0.0303\n",
            "Epoch 2/20\n",
            "98/98 [==============================] - 185s 2s/step - loss: 3.1966 - accuracy: 0.0839 - val_loss: 3.3959 - val_accuracy: 0.1010\n",
            "Epoch 3/20\n",
            "98/98 [==============================] - 184s 2s/step - loss: 3.0831 - accuracy: 0.1179 - val_loss: 3.0100 - val_accuracy: 0.1448\n",
            "Epoch 4/20\n",
            "98/98 [==============================] - 183s 2s/step - loss: 2.8334 - accuracy: 0.1717 - val_loss: 2.9145 - val_accuracy: 0.1515\n",
            "Epoch 5/20\n",
            "98/98 [==============================] - 181s 2s/step - loss: 2.7156 - accuracy: 0.2159 - val_loss: 2.8042 - val_accuracy: 0.1616\n",
            "Epoch 6/20\n",
            "98/98 [==============================] - 181s 2s/step - loss: 2.4780 - accuracy: 0.2582 - val_loss: 2.6612 - val_accuracy: 0.2189\n",
            "Epoch 7/20\n",
            "98/98 [==============================] - 181s 2s/step - loss: 2.2492 - accuracy: 0.3261 - val_loss: 2.5455 - val_accuracy: 0.2559\n",
            "Epoch 8/20\n",
            "98/98 [==============================] - 182s 2s/step - loss: 2.0596 - accuracy: 0.3786 - val_loss: 2.3827 - val_accuracy: 0.2761\n",
            "Epoch 9/20\n",
            "98/98 [==============================] - 189s 2s/step - loss: 1.7773 - accuracy: 0.4600 - val_loss: 2.2411 - val_accuracy: 0.3300\n",
            "Epoch 10/20\n",
            "98/98 [==============================] - 188s 2s/step - loss: 1.6037 - accuracy: 0.4997 - val_loss: 2.4570 - val_accuracy: 0.2997\n",
            "Epoch 11/20\n",
            "98/98 [==============================] - 184s 2s/step - loss: 1.5029 - accuracy: 0.5215 - val_loss: 2.1180 - val_accuracy: 0.3872\n",
            "Epoch 12/20\n",
            "98/98 [==============================] - 181s 2s/step - loss: 1.2690 - accuracy: 0.6028 - val_loss: 2.1618 - val_accuracy: 0.4175\n",
            "Epoch 13/20\n",
            "98/98 [==============================] - 182s 2s/step - loss: 1.1329 - accuracy: 0.6432 - val_loss: 2.0241 - val_accuracy: 0.3973\n",
            "Epoch 14/20\n",
            "98/98 [==============================] - 179s 2s/step - loss: 1.1817 - accuracy: 0.6323 - val_loss: 1.9907 - val_accuracy: 0.4343\n",
            "Epoch 15/20\n",
            "98/98 [==============================] - 179s 2s/step - loss: 0.9862 - accuracy: 0.6925 - val_loss: 2.1348 - val_accuracy: 0.4545\n",
            "Epoch 16/20\n",
            "98/98 [==============================] - 180s 2s/step - loss: 0.8186 - accuracy: 0.7476 - val_loss: 1.9624 - val_accuracy: 0.4949\n",
            "Epoch 17/20\n",
            "98/98 [==============================] - 179s 2s/step - loss: 0.8291 - accuracy: 0.7399 - val_loss: 1.8342 - val_accuracy: 0.4882\n",
            "Epoch 18/20\n",
            "98/98 [==============================] - 181s 2s/step - loss: 0.7961 - accuracy: 0.7553 - val_loss: 1.9888 - val_accuracy: 0.4815\n",
            "Epoch 19/20\n",
            "98/98 [==============================] - 178s 2s/step - loss: 0.6100 - accuracy: 0.8104 - val_loss: 2.5051 - val_accuracy: 0.5017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAS0RR_jhsfI"
      },
      "source": [
        "## Saving model to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAnrWeRXhva6"
      },
      "source": [
        "CNN.save('hand_gesture_classifier.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flOnxIQROl4_"
      },
      "source": [
        "# Results\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtaLSZAtgzPK",
        "outputId": "0141e6b2-53f7-4142-fe0d-00b3bb25dcea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "metrics = pd.DataFrame(CNN.history.history)\n",
        "metrics"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.343206</td>\n",
              "      <td>0.044843</td>\n",
              "      <td>3.287111</td>\n",
              "      <td>0.030303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.196588</td>\n",
              "      <td>0.083921</td>\n",
              "      <td>3.395883</td>\n",
              "      <td>0.101010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.083059</td>\n",
              "      <td>0.117873</td>\n",
              "      <td>3.010034</td>\n",
              "      <td>0.144781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.833420</td>\n",
              "      <td>0.171685</td>\n",
              "      <td>2.914515</td>\n",
              "      <td>0.151515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.715626</td>\n",
              "      <td>0.215887</td>\n",
              "      <td>2.804249</td>\n",
              "      <td>0.161616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.477994</td>\n",
              "      <td>0.258168</td>\n",
              "      <td>2.661197</td>\n",
              "      <td>0.218855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.249238</td>\n",
              "      <td>0.326073</td>\n",
              "      <td>2.545473</td>\n",
              "      <td>0.255892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.059560</td>\n",
              "      <td>0.378603</td>\n",
              "      <td>2.382671</td>\n",
              "      <td>0.276094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.777272</td>\n",
              "      <td>0.459962</td>\n",
              "      <td>2.241129</td>\n",
              "      <td>0.329966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.603663</td>\n",
              "      <td>0.499680</td>\n",
              "      <td>2.456973</td>\n",
              "      <td>0.299663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.502920</td>\n",
              "      <td>0.521461</td>\n",
              "      <td>2.118035</td>\n",
              "      <td>0.387205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.268989</td>\n",
              "      <td>0.602819</td>\n",
              "      <td>2.161831</td>\n",
              "      <td>0.417508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.132946</td>\n",
              "      <td>0.643177</td>\n",
              "      <td>2.024060</td>\n",
              "      <td>0.397306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.181715</td>\n",
              "      <td>0.632287</td>\n",
              "      <td>1.990700</td>\n",
              "      <td>0.434343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.986178</td>\n",
              "      <td>0.692505</td>\n",
              "      <td>2.134848</td>\n",
              "      <td>0.454545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.818625</td>\n",
              "      <td>0.747598</td>\n",
              "      <td>1.962421</td>\n",
              "      <td>0.494949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.829129</td>\n",
              "      <td>0.739910</td>\n",
              "      <td>1.834183</td>\n",
              "      <td>0.488215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.796137</td>\n",
              "      <td>0.755285</td>\n",
              "      <td>1.988790</td>\n",
              "      <td>0.481481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.610021</td>\n",
              "      <td>0.810378</td>\n",
              "      <td>2.505065</td>\n",
              "      <td>0.501683</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy\n",
              "0   3.343206  0.044843  3.287111      0.030303\n",
              "1   3.196588  0.083921  3.395883      0.101010\n",
              "2   3.083059  0.117873  3.010034      0.144781\n",
              "3   2.833420  0.171685  2.914515      0.151515\n",
              "4   2.715626  0.215887  2.804249      0.161616\n",
              "5   2.477994  0.258168  2.661197      0.218855\n",
              "6   2.249238  0.326073  2.545473      0.255892\n",
              "7   2.059560  0.378603  2.382671      0.276094\n",
              "8   1.777272  0.459962  2.241129      0.329966\n",
              "9   1.603663  0.499680  2.456973      0.299663\n",
              "10  1.502920  0.521461  2.118035      0.387205\n",
              "11  1.268989  0.602819  2.161831      0.417508\n",
              "12  1.132946  0.643177  2.024060      0.397306\n",
              "13  1.181715  0.632287  1.990700      0.434343\n",
              "14  0.986178  0.692505  2.134848      0.454545\n",
              "15  0.818625  0.747598  1.962421      0.494949\n",
              "16  0.829129  0.739910  1.834183      0.488215\n",
              "17  0.796137  0.755285  1.988790      0.481481\n",
              "18  0.610021  0.810378  2.505065      0.501683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFytDgrDOzFi"
      },
      "source": [
        "## Single image prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOhVHB_8VBdH",
        "outputId": "eb947f90-9a7a-49ad-91c0-a453d06f8d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "nmb = 2\n",
        "my_hand = X_test[nmb]\n",
        "show_img(nmb, X_test, Y_cat_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-bba7f04db06b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnmb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_hand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnmb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mshow_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnmb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3AUJxpIW5or"
      },
      "source": [
        "my_hand = my_hand.reshape(1, vert_y, horiz_x, 3)\n",
        "result = CNN.predict_classes(my_hand)\n",
        "# result = (CNN.predict(my_hand) > 0.5).astype(\"int32\")\n",
        "result = int(result)\n",
        "print('CNN says: ' + class_names[result])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQsDgI5RO3lm"
      },
      "source": [
        "## Predictions for individual classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1CCpmyR-o_O"
      },
      "source": [
        "predictions = CNN.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv3EpAC2XDKz"
      },
      "source": [
        "print(classification_report(Y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAVH-aNsDY0F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}